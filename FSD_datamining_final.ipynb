{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FSD_datamining_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzJpt5NnMgj1",
        "outputId": "e79d8dcf-2011-4976-c9f2-385242ec0d47"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy248omaMpzW",
        "outputId": "642f89a9-3858-428a-c328-a5d608e1a9f1"
      },
      "source": [
        "%cd drive/MyDrive/data mining"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/data mining\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AZoMh_rwnb6"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caBVximrwnb_"
      },
      "source": [
        "file_path='data/train_2.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktxkyzC1wncA"
      },
      "source": [
        "def loadInputFile(file_path):\n",
        "    trainingset = list()  # store trainingset [content,content,...]\n",
        "    position = list()  # store position [article_id, start_pos, end_pos, entity_text, entity_type, ...]\n",
        "    mentions = dict()  # store mentions[mention] = Type\n",
        "    with open(file_path, 'r', encoding='utf8') as f:\n",
        "        file_text=f.read().encode('utf-8').decode('utf-8-sig')\n",
        "    datas=file_text.split('\\n\\n--------------------\\n\\n')[:-1]\n",
        "    for data in datas:\n",
        "        data=data.split('\\n')\n",
        "        content=data[0]\n",
        "        trainingset.append(content)\n",
        "        annotations=data[1:]\n",
        "        for annot in annotations[1:]:\n",
        "            annot=annot.split('\\t') #annot= article_id, start_pos, end_pos, entity_text, entity_type\n",
        "            position.extend(annot)\n",
        "            mentions[annot[3]]=annot[4]\n",
        "    \n",
        "    return trainingset, position, mentions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ECE1JTkwncA"
      },
      "source": [
        "def CRFFormatData(trainingset, position, path):\n",
        "    if (os.path.isfile(path)):\n",
        "        os.remove(path)\n",
        "    outputfile = open(path, 'a', encoding= 'utf-8')\n",
        "\n",
        "    # output file lines\n",
        "    count = 0 # annotation counts in each content\n",
        "    tagged = list()\n",
        "    for article_id in range(len(trainingset)):\n",
        "        trainingset_split = list(trainingset[article_id])\n",
        "        while '' or ' ' in trainingset_split:\n",
        "            if '' in trainingset_split:\n",
        "                trainingset_split.remove('')\n",
        "            else:\n",
        "                trainingset_split.remove(' ')\n",
        "        start_tmp = 0\n",
        "        for position_idx in range(0,len(position),5):\n",
        "            if int(position[position_idx]) == article_id:\n",
        "                count += 1\n",
        "                if count == 1:\n",
        "                    start_pos = int(position[position_idx+1])\n",
        "                    end_pos = int(position[position_idx+2])\n",
        "                    entity_type=position[position_idx+4]\n",
        "                    if start_pos == 0:\n",
        "                        token = list(trainingset[article_id][start_pos:end_pos])\n",
        "                        whole_token = trainingset[article_id][start_pos:end_pos]\n",
        "                        for token_idx in range(len(token)):\n",
        "                            if len(token[token_idx].replace(' ','')) == 0:\n",
        "                                continue\n",
        "                            # BIO states\n",
        "                            if token_idx == 0:\n",
        "                                label = 'B-'+entity_type\n",
        "                            else:\n",
        "                                label = 'I-'+entity_type\n",
        "                            \n",
        "                            output_str = token[token_idx] + ' ' + label + '\\n'\n",
        "                            outputfile.write(output_str)\n",
        "\n",
        "                    else:\n",
        "                        token = list(trainingset[article_id][0:start_pos])\n",
        "                        whole_token = trainingset[article_id][0:start_pos]\n",
        "                        for token_idx in range(len(token)):\n",
        "                            if len(token[token_idx].replace(' ','')) == 0:\n",
        "                                continue\n",
        "                            \n",
        "                            output_str = token[token_idx] + ' ' + 'O' + '\\n'\n",
        "                            outputfile.write(output_str)\n",
        "\n",
        "                        token = list(trainingset[article_id][start_pos:end_pos])\n",
        "                        whole_token = trainingset[article_id][start_pos:end_pos]\n",
        "                        for token_idx in range(len(token)):\n",
        "                            if len(token[token_idx].replace(' ','')) == 0:\n",
        "                                continue\n",
        "                            # BIO states\n",
        "                            if token[0] == '':\n",
        "                                if token_idx == 1:\n",
        "                                    label = 'B-'+entity_type\n",
        "                                else:\n",
        "                                    label = 'I-'+entity_type\n",
        "                            else:\n",
        "                                if token_idx == 0:\n",
        "                                    label = 'B-'+entity_type\n",
        "                                else:\n",
        "                                    label = 'I-'+entity_type\n",
        "\n",
        "                            output_str = token[token_idx] + ' ' + label + '\\n'\n",
        "                            outputfile.write(output_str)\n",
        "\n",
        "                    start_tmp = end_pos\n",
        "                else:\n",
        "                    start_pos = int(position[position_idx+1])\n",
        "                    end_pos = int(position[position_idx+2])\n",
        "                    entity_type=position[position_idx+4]\n",
        "                    if start_pos<start_tmp:\n",
        "                        continue\n",
        "                    else:\n",
        "                        token = list(trainingset[article_id][start_tmp:start_pos])\n",
        "                        whole_token = trainingset[article_id][start_tmp:start_pos]\n",
        "                        for token_idx in range(len(token)):\n",
        "                            if len(token[token_idx].replace(' ','')) == 0:\n",
        "                                continue\n",
        "                            output_str = token[token_idx] + ' ' + 'O' + '\\n'\n",
        "                            outputfile.write(output_str)\n",
        "\n",
        "                    token = list(trainingset[article_id][start_pos:end_pos])\n",
        "                    whole_token = trainingset[article_id][start_pos:end_pos]\n",
        "                    for token_idx in range(len(token)):\n",
        "                        if len(token[token_idx].replace(' ','')) == 0:\n",
        "                            continue\n",
        "                        # BIO states\n",
        "                        if token[0] == '':\n",
        "                            if token_idx == 1:\n",
        "                                label = 'B-'+entity_type\n",
        "                            else:\n",
        "                                label = 'I-'+entity_type\n",
        "                        else:\n",
        "                            if token_idx == 0:\n",
        "                                label = 'B-'+entity_type\n",
        "                            else:\n",
        "                                label = 'I-'+entity_type\n",
        "                        \n",
        "                        output_str = token[token_idx] + ' ' + label + '\\n'\n",
        "                        outputfile.write(output_str)\n",
        "                    start_tmp = end_pos\n",
        "\n",
        "        token = list(trainingset[article_id][start_tmp:])\n",
        "        whole_token = trainingset[article_id][start_tmp:]\n",
        "        for token_idx in range(len(token)):\n",
        "            if len(token[token_idx].replace(' ','')) == 0:\n",
        "                continue\n",
        "\n",
        "            \n",
        "            output_str = token[token_idx] + ' ' + 'O' + '\\n'\n",
        "            outputfile.write(output_str)\n",
        "\n",
        "        count = 0\n",
        "    \n",
        "        output_str = '\\n'\n",
        "        outputfile.write(output_str)\n",
        "        ID = trainingset[article_id]\n",
        "\n",
        "        if article_id%10 == 0:\n",
        "            print('Total complete articles:', article_id)\n",
        "\n",
        "    # close output file\n",
        "    outputfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT4HaWc4wncB",
        "outputId": "bdc2359a-40fc-4ffa-cdf8-c65eb9964810"
      },
      "source": [
        "trainingset, position, mentions=loadInputFile(file_path)\n",
        "data_path='data/sample.data'\n",
        "CRFFormatData(trainingset, position, data_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total complete articles: 0\n",
            "Total complete articles: 10\n",
            "Total complete articles: 20\n",
            "Total complete articles: 30\n",
            "Total complete articles: 40\n",
            "Total complete articles: 50\n",
            "Total complete articles: 60\n",
            "Total complete articles: 70\n",
            "Total complete articles: 80\n",
            "Total complete articles: 90\n",
            "Total complete articles: 100\n",
            "Total complete articles: 110\n",
            "Total complete articles: 120\n",
            "Total complete articles: 130\n",
            "Total complete articles: 140\n",
            "Total complete articles: 150\n",
            "Total complete articles: 160\n",
            "Total complete articles: 170\n",
            "Total complete articles: 180\n",
            "Total complete articles: 190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7ZZw_ZqwncC",
        "outputId": "71fadddf-1f55-4589-93c0-a234eb29c99b"
      },
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.9.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mERCg5xxwncD"
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn_crfsuite.metrics import flat_classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzbTrD2zwncD"
      },
      "source": [
        "# load `train.data` and separate into a list of labeled data of each text\n",
        "# return:\n",
        "#   data_list: a list of lists of tuples, storing tokens and labels (wrapped in tuple) of each text in `train.data`\n",
        "#   traindata_list: a list of lists, storing training data_list splitted from data_list\n",
        "#   testdata_list: a list of lists, storing testing data_list splitted from data_list\n",
        "from sklearn.model_selection import train_test_split\n",
        "def Dataset(data_path):\n",
        "    with open(data_path, 'r', encoding='utf-8') as f:\n",
        "        data=f.readlines()#.encode('utf-8').decode('utf-8-sig')\n",
        "    data_list, data_list_tmp = list(), list()\n",
        "    article_id_list=list()\n",
        "    idx=0\n",
        "    for row in data:\n",
        "        data_tuple = tuple()\n",
        "        if row == '\\n':\n",
        "            article_id_list.append(idx)\n",
        "            idx+=1\n",
        "            data_list.append(data_list_tmp)\n",
        "            data_list_tmp = []\n",
        "        else:\n",
        "            row = row.strip('\\n').split(' ')\n",
        "            data_tuple = (row[0], row[1])\n",
        "            data_list_tmp.append(data_tuple)\n",
        "    if len(data_list_tmp) != 0:\n",
        "        data_list.append(data_list_tmp)\n",
        "    \n",
        "    # here we random split data into training dataset and testing dataset\n",
        "    # but you should take `development data` or `test data` as testing data\n",
        "    # At that time, you could just delete this line, \n",
        "    # and generate data_list of `train data` and data_list of `development/test data` by this function\n",
        "    traindata_list, testdata_list, traindata_article_id_list, testdata_article_id_list=train_test_split(data_list,\n",
        "                                                                                                    article_id_list,\n",
        "                                                                                                    test_size=0.2,\n",
        "                                                                                                    random_state=42)\n",
        "    \n",
        "    return data_list, traindata_list, testdata_list, traindata_article_id_list, testdata_article_id_list "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95AasiNbwncD"
      },
      "source": [
        "data_list, traindata_list, testdata_list, traindata_article_id_list, testdata_article_id_list = Dataset(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSwabjcewncE"
      },
      "source": [
        "totaldata_list = traindata_list + testdata_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAC9OCJSwncG"
      },
      "source": [
        "def strQ2B(ustring):\n",
        "    \"\"\"把字串全形轉半形\"\"\"\n",
        "    ss = []\n",
        "    for s in ustring:\n",
        "        rstring = \"\"\n",
        "        for uchar in s:\n",
        "            inside_code = ord(uchar)\n",
        "            if inside_code == 12288:  # 全形空格直接轉換\n",
        "                inside_code = 32\n",
        "            elif (inside_code >= 65281 and inside_code <= 65374):  # 全形字元（除空格）根據關係轉化\n",
        "                inside_code -= 65248\n",
        "            rstring += chr(inside_code)\n",
        "        ss.append(rstring)\n",
        "    return ''.join(ss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "275FVppdwncH"
      },
      "source": [
        "#最大句號長度\n",
        "def max_dot_split(traindata_list,max_seqence=512):\n",
        "    totalSeq = []\n",
        "    totalValue = []\n",
        "    max_seqence = max_seqence\n",
        "    for article in traindata_list:\n",
        "        #print(article)\n",
        "        seqText = []\n",
        "        seqValue = []\n",
        "        batch_seq_text = []\n",
        "        batch_seq_value = []\n",
        "        batch_length  = 0\n",
        "        seq_length = 0\n",
        "\n",
        "        for index in range(len(article)):\n",
        "\n",
        "            word = article[index][0]\n",
        "            word = strQ2B(word)\n",
        "            value = article[index][1]\n",
        "            #seqText += word+'\\x02'\n",
        "            #seqValue += value+'\\x02'\n",
        "            seqText.append(word)\n",
        "            seqValue.append(value)\n",
        "            seq_length += 1\n",
        "\n",
        "            if(word == '。'):\n",
        "                batch_length += seq_length\n",
        "                if(batch_length <= max_seqence):\n",
        "                    batch_seq_text += seqText\n",
        "                    batch_seq_value += seqValue\n",
        "                    seq_length = 0\n",
        "\n",
        "                if(batch_length > max_seqence):\n",
        "                    #print('a batch', len(batch_seq_text))\n",
        "                    totalSeq.append(batch_seq_text)\n",
        "                    totalValue.append(batch_seq_value)\n",
        "                    if(index == len(article)-1):\n",
        "                        totalSeq.append(seqText)\n",
        "                        totalValue.append(seqValue)\n",
        "                        #print('a batch', len(seqText))\n",
        "                    batch_length = seq_length\n",
        "                    batch_seq_text = seqText\n",
        "                    batch_seq_value = seqValue\n",
        "                    seq_length = 0\n",
        "                \n",
        "                seqText = []\n",
        "                seqValue = []\n",
        "    return totalSeq,totalValue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxmwutErwncH"
      },
      "source": [
        "train_x,train_y = max_dot_split(traindata_list,128)\n",
        "valid_x, valid_y = max_dot_split(testdata_list,128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMUzP6MbwncH",
        "outputId": "52c4b653-e1ad-475f-d6b6-e15fb27eab00"
      },
      "source": [
        "!pip install \"kashgari>=1.1,<2.0\"\n",
        "!pip install \"tensorflow-gpu>=1.14,<2.0\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kashgari<2.0,>=1.1 in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: bert4keras==0.6.5 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0,>=1.1) (0.6.5)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0,>=1.1) (1.1.5)\n",
            "Requirement already satisfied: keras-bert>=0.50.0 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0,>=1.1) (0.86.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0,>=1.1) (2.10.0)\n",
            "Requirement already satisfied: keras-gpt-2>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0,>=1.1) (0.15.0)\n",
            "Requirement already satisfied: seqeval==0.0.10 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0,>=1.1) (0.0.10)\n",
            "Requirement already satisfied: gensim>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0,>=1.1) (3.6.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0,>=1.1) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy==1.16.4 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0,>=1.1) (1.16.4)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from bert4keras==0.6.5->kashgari<2.0,>=1.1) (2.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->kashgari<2.0,>=1.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->kashgari<2.0,>=1.1) (2018.9)\n",
            "Requirement already satisfied: keras-transformer>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from keras-bert>=0.50.0->kashgari<2.0,>=1.1) (0.38.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->kashgari<2.0,>=1.1) (1.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from keras-gpt-2>=0.8.0->kashgari<2.0,>=1.1) (2019.12.20)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.5.0->kashgari<2.0,>=1.1) (4.0.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.5.0->kashgari<2.0,>=1.1) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.1->kashgari<2.0,>=1.1) (1.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras==0.6.5->kashgari<2.0,>=1.1) (3.13)\n",
            "Requirement already satisfied: keras-embed-sim>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.50.0->kashgari<2.0,>=1.1) (0.8.0)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.50.0->kashgari<2.0,>=1.1) (0.14.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.50.0->kashgari<2.0,>=1.1) (0.11.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.50.0->kashgari<2.0,>=1.1) (0.6.0)\n",
            "Requirement already satisfied: keras-multi-head>=0.27.0 in /usr/local/lib/python3.6/dist-packages (from keras-transformer>=0.38.0->keras-bert>=0.50.0->kashgari<2.0,>=1.1) (0.27.0)\n",
            "Requirement already satisfied: keras-self-attention==0.46.0 in /usr/local/lib/python3.6/dist-packages (from keras-multi-head>=0.27.0->keras-transformer>=0.38.0->keras-bert>=0.50.0->kashgari<2.0,>=1.1) (0.46.0)\n",
            "Requirement already satisfied: tensorflow-gpu<2.0,>=1.14 in /usr/local/lib/python3.6/dist-packages (1.15.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (0.2.2)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (1.16.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (1.32.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (1.15.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2.0,>=1.14) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2.0,>=1.14) (51.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2.0,>=1.14) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2.0,>=1.14) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu<2.0,>=1.14) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2.0,>=1.14) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2.0,>=1.14) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2.0,>=1.14) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSqLGLBnwncI"
      },
      "source": [
        "# from kashgari.corpus import ChineseDailyNerCorpus\n",
        "\n",
        "# train_x, train_y = ChineseDailyNerCorpus.load_data('train')\n",
        "# valid_x, valid_y = ChineseDailyNerCorpus.load_data('validate')\n",
        "# test_x, test_y  = ChineseDailyNerCorpus.load_data('test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEfT-HkawncI"
      },
      "source": [
        "# !unzip data/data65800/chinese_wwm_ext_L-12_H-768_A-12.zip -d bert \n",
        "# !unzip data/data65800/roeberta_zh_L-24_H-1024_A-16.zip -d roberta "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bX-UnckswncI",
        "outputId": "c39b7139-dc19-4af7-e17c-22345382d8b8"
      },
      "source": [
        "import kashgari\n",
        "from kashgari.embeddings import BERTEmbedding\n",
        "\n",
        "bert_embed = BERTEmbedding('embeddings/chinese_wwm_ext_L-12_H-768_A-12',\n",
        "                           task=kashgari.LABELING,\n",
        "                           sequence_length=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:CUDA GPU available, you can set `kashgari.config.use_cudnn_cell = True` to use CuDNNCell. This will speed up the training, but will make model incompatible with CPU device.\n",
            "/usr/local/lib/python3.6/dist-packages/bert4keras/__init__.py:22: UserWarning: bert4keras.bert has been renamed as bert4keras.models.\n",
            "  warnings.warn('bert4keras.bert has been renamed as bert4keras.models.')\n",
            "/usr/local/lib/python3.6/dist-packages/bert4keras/__init__.py:23: UserWarning: please use bert4keras.models.\n",
            "  warnings.warn('please use bert4keras.models.')\n",
            "/usr/local/lib/python3.6/dist-packages/bert4keras/__init__.py:44: UserWarning: bert4keras.tokenizer has been renamed as bert4keras.tokenizers.\n",
            "  warnings.warn('bert4keras.tokenizer has been renamed as bert4keras.tokenizers.')\n",
            "/usr/local/lib/python3.6/dist-packages/bert4keras/__init__.py:45: UserWarning: please use bert4keras.tokenizers.\n",
            "  warnings.warn('please use bert4keras.tokenizers.')\n",
            "WARNING:root:seq_len: 128\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvXSEzEswncJ"
      },
      "source": [
        "# import os\n",
        "# import kashgari\n",
        "# from kashgari.embeddings import TransformerEmbedding\n",
        "# from kashgari.tokenizer import BertTokenizer \n",
        "# # Setup paths\n",
        "# model_folder = ''\n",
        "# checkpoint_path = os.path.join(model_folder, 'roberta_zh_large_model.ckpt.data-00000-of-00001')\n",
        "# config_path = os.path.join(model_folder, 'bert_config.json')\n",
        "# vocab_path = os.path.join(model_folder, 'vocab.txt')\n",
        "\n",
        "# tokenizer = BertTokenizer.load_from_vocab_file(vocab_path)\n",
        "# embed = TransformerEmbedding(vocab_path, config_path, checkpoint_path,\n",
        "#                              bert_type='roberta')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxVVfpLMwncJ",
        "outputId": "13a48cde-db5c-44eb-b710-a4d411755cbf"
      },
      "source": [
        "from kashgari.tasks.labeling import BiLSTM_CRF_Model\n",
        "\n",
        "# 还可以选择 `CNN_LSTM_Model`, `BiLSTM_Model`, `BiGRU_Model` 或 `BiGRU_CRF_Model`\n",
        "\n",
        "model = BiLSTM_CRF_Model(bert_embed)\n",
        "model.fit(train_x,\n",
        "          train_y,\n",
        "          x_validate=valid_x,\n",
        "          y_validate=valid_y,\n",
        "          epochs=20,\n",
        "          batch_size=8)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bert4keras/__init__.py:22: UserWarning: bert4keras.bert has been renamed as bert4keras.models.\n",
            "  warnings.warn('bert4keras.bert has been renamed as bert4keras.models.')\n",
            "/usr/local/lib/python3.6/dist-packages/bert4keras/__init__.py:23: UserWarning: please use bert4keras.models.\n",
            "  warnings.warn('please use bert4keras.models.')\n",
            "/usr/local/lib/python3.6/dist-packages/bert4keras/__init__.py:44: UserWarning: bert4keras.tokenizer has been renamed as bert4keras.tokenizers.\n",
            "  warnings.warn('bert4keras.tokenizer has been renamed as bert4keras.tokenizers.')\n",
            "/usr/local/lib/python3.6/dist-packages/bert4keras/__init__.py:45: UserWarning: please use bert4keras.tokenizers.\n",
            "  warnings.warn('please use bert4keras.tokenizers.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 128, 768), ( 16226304    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 128, 768)     1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 128, 768)     0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 128, 768)     98304       Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 128, 768)     0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 128, 768)     1536        Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     2362368     Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-5-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-6-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-7-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-8-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-9-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout  (None, 128, 768)     0           Encoder-10-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout  (None, 128, 768)     0           Encoder-11-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout  (None, 128, 768)     0           Encoder-12-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Output (Concatenate)    (None, 128, 3072)    0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "non_masking_layer (NonMaskingLa (None, 128, 3072)    0           Encoder-Output[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "layer_blstm (Bidirectional)     (None, 128, 256)     3277824     non_masking_layer[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "layer_dense (Dense)             (None, 128, 64)      16448       layer_blstm[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "layer_crf_dense (Dense)         (None, 128, 28)      1820        layer_dense[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "layer_crf (CRF)                 (None, 128, 28)      784         layer_crf_dense[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 104,679,020\n",
            "Trainable params: 3,296,876\n",
            "Non-trainable params: 101,382,144\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 9.9302 - accuracy: 0.9796Epoch 1/20\n",
            "361/361 [==============================] - 470s 1s/step - loss: 9.9031 - accuracy: 0.9796 - val_loss: 291.0334 - val_accuracy: 0.9874\n",
            "Epoch 2/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 3.7393 - accuracy: 0.9890Epoch 1/20\n",
            "361/361 [==============================] - 463s 1s/step - loss: 3.7292 - accuracy: 0.9890 - val_loss: 283.8146 - val_accuracy: 0.9877\n",
            "Epoch 3/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 2.9010 - accuracy: 0.9905Epoch 1/20\n",
            "361/361 [==============================] - 463s 1s/step - loss: 2.9348 - accuracy: 0.9905 - val_loss: 276.9160 - val_accuracy: 0.9899\n",
            "Epoch 4/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 2.4381 - accuracy: 0.9913Epoch 1/20\n",
            "361/361 [==============================] - 461s 1s/step - loss: 2.4322 - accuracy: 0.9913 - val_loss: 270.3326 - val_accuracy: 0.9887\n",
            "Epoch 5/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 2.0082 - accuracy: 0.9920Epoch 1/20\n",
            "361/361 [==============================] - 460s 1s/step - loss: 2.0035 - accuracy: 0.9920 - val_loss: 263.8016 - val_accuracy: 0.9882\n",
            "Epoch 6/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 1.7603 - accuracy: 0.9923Epoch 1/20\n",
            "361/361 [==============================] - 459s 1s/step - loss: 1.7611 - accuracy: 0.9923 - val_loss: 257.4846 - val_accuracy: 0.9891\n",
            "Epoch 7/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 1.5230 - accuracy: 0.9930Epoch 1/20\n",
            "361/361 [==============================] - 459s 1s/step - loss: 1.5188 - accuracy: 0.9930 - val_loss: 251.9317 - val_accuracy: 0.9879\n",
            "Epoch 8/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 1.4054 - accuracy: 0.9932Epoch 1/20\n",
            "361/361 [==============================] - 456s 1s/step - loss: 1.4069 - accuracy: 0.9932 - val_loss: 246.4012 - val_accuracy: 0.9875\n",
            "Epoch 9/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 1.2850 - accuracy: 0.9933Epoch 1/20\n",
            "361/361 [==============================] - 458s 1s/step - loss: 1.2835 - accuracy: 0.9933 - val_loss: 240.6722 - val_accuracy: 0.9883\n",
            "Epoch 10/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 1.1375 - accuracy: 0.9941Epoch 1/20\n",
            "361/361 [==============================] - 458s 1s/step - loss: 1.1344 - accuracy: 0.9941 - val_loss: 235.8153 - val_accuracy: 0.9879\n",
            "Epoch 11/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 0.9276 - accuracy: 0.9951Epoch 1/20\n",
            "361/361 [==============================] - 458s 1s/step - loss: 0.9371 - accuracy: 0.9951 - val_loss: 231.4892 - val_accuracy: 0.9889\n",
            "Epoch 12/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 0.8995 - accuracy: 0.9949Epoch 1/20\n",
            "361/361 [==============================] - 459s 1s/step - loss: 0.8971 - accuracy: 0.9949 - val_loss: 226.8458 - val_accuracy: 0.9867\n",
            "Epoch 13/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 0.8651 - accuracy: 0.9950Epoch 1/20\n",
            "361/361 [==============================] - 458s 1s/step - loss: 0.8653 - accuracy: 0.9950 - val_loss: 222.8737 - val_accuracy: 0.9886\n",
            "Epoch 14/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 0.7690 - accuracy: 0.9954Epoch 1/20\n",
            "361/361 [==============================] - 459s 1s/step - loss: 0.7700 - accuracy: 0.9954 - val_loss: 218.9917 - val_accuracy: 0.9797\n",
            "Epoch 15/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 0.7337 - accuracy: 0.9954Epoch 1/20\n",
            "361/361 [==============================] - 459s 1s/step - loss: 0.7326 - accuracy: 0.9954 - val_loss: 215.6762 - val_accuracy: 0.9777\n",
            "Epoch 16/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 0.7520 - accuracy: 0.9954Epoch 1/20\n",
            "361/361 [==============================] - 458s 1s/step - loss: 0.7503 - accuracy: 0.9954 - val_loss: 211.2448 - val_accuracy: 0.9796\n",
            "Epoch 17/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 0.6677 - accuracy: 0.9957Epoch 1/20\n",
            "361/361 [==============================] - 458s 1s/step - loss: 0.6659 - accuracy: 0.9957 - val_loss: 208.3861 - val_accuracy: 0.9781\n",
            "Epoch 18/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 0.5881 - accuracy: 0.9964Epoch 1/20\n",
            "361/361 [==============================] - 458s 1s/step - loss: 0.5894 - accuracy: 0.9964 - val_loss: 205.1236 - val_accuracy: 0.9083\n",
            "Epoch 19/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 0.5594 - accuracy: 0.9964Epoch 1/20\n",
            "361/361 [==============================] - 459s 1s/step - loss: 0.5578 - accuracy: 0.9964 - val_loss: 202.0600 - val_accuracy: 0.8613\n",
            "Epoch 20/20\n",
            "360/361 [============================>.] - ETA: 1s - loss: 0.5322 - accuracy: 0.9964Epoch 1/20\n",
            "361/361 [==============================] - 458s 1s/step - loss: 0.5308 - accuracy: 0.9964 - val_loss: 199.2208 - val_accuracy: 0.8608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe1cce3ffd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnEMeAjhMYDp"
      },
      "source": [
        "model.save('model_save')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICvG9AWsfbfH"
      },
      "source": [
        "def get_format_article_result(atricle_id,total_label_tags, total_sentence_str):\n",
        "    article_result = []\n",
        "\n",
        "    entiy = ''\n",
        "    start_position = 0\n",
        "    end_position = 0\n",
        "    current_length = 0\n",
        "\n",
        "    for index in range(len(total_label_tags)):\n",
        "        label_tag = total_label_tags[index]\n",
        "        #print('index:', index)\n",
        "        # if(entiy != ''):\n",
        "        #     print(index,current_length,entiy)\n",
        "        if(label_tag.startswith('B-')):\n",
        "            #if it is a new B, record last entiy\n",
        "            if(current_length>=2):\n",
        "                end_position = index\n",
        "                article_result.append([atricle_id,start_position,end_position,entiy,entity_type])\n",
        "                #print('record:',[atricle_id,start_position,end_position,entiy,entity_type])\n",
        "                #record_entiy()\n",
        "\n",
        "            entiy = ''\n",
        "            start_position = 0\n",
        "            end_position = 0\n",
        "            current_length = 0\n",
        "\n",
        "            #find the entiy at B-\n",
        "            #if(current_length == 0):\n",
        "            entiy += total_sentence_str[index]\n",
        "            start_position = index\n",
        "            #print('start position: ', start_position)\n",
        "            entity_type = label_tag.split(\"-\")[1]\n",
        "            current_length += 1\n",
        "                \n",
        "        \n",
        "        if(label_tag.startswith('I-')):\n",
        "            if(index>=1):\n",
        "                # if the last label is B-\n",
        "                if(current_length >= 1):\n",
        "                    if(total_label_tags[index-1].split(\"-\")[1] == label_tag.split(\"-\")[1]):\n",
        "                        entiy += total_sentence_str[index]\n",
        "                        current_length += 1 \n",
        "                    if(total_label_tags[index-1].split(\"-\")[1] != label_tag.split(\"-\")[1]):\n",
        "                        if(current_length>=2):\n",
        "                            end_position = index\n",
        "                            article_result.append([atricle_id,start_position,end_position,entiy,entity_type])\n",
        "                        entiy = ''\n",
        "                        start_position = 0\n",
        "                        end_position = 0\n",
        "                        current_length = 0\n",
        "                # if((total_label_tags[index-1].startswith('B-') and total_label_tags[index-1].split(\"-\")[1] != label_tag.split(\"-\")[1]) or (total_label_tags[index-1].startswith('I-') and total_label_tags[index-1].split(\"-\")[1] != label_tag.split(\"-\")[1])):\n",
        "                #     #print('detect')\n",
        "                #     # if the label type is not same as the last one\n",
        "                #     #if(total_label_tags[index-1].split(\"-\")[1] != label_tag.split(\"-\")[1]):\n",
        "                #     # reinint parm\n",
        "                #     entiy = ''\n",
        "                #     start_position = 0\n",
        "                #     end_position = 0\n",
        "                #     current_length = 0\n",
        "                    \n",
        "                #     # find the entiy by I-\n",
        "                #     entiy += total_sentence_str[index]\n",
        "                #     start_position = index\n",
        "                #     entity_type = label_tag.split(\"-\")[1]\n",
        "                #     current_length += 1\n",
        "                # if the last label is not B-, continue the count\n",
        "                #if(total_label_tags[index-1].startswith('I-') and total_label_tags[index-1].split(\"-\")[1] != label_tag.split(\"-\")[1])\n",
        "                #else: \n",
        "\n",
        "        if(label_tag == 'O'):\n",
        "            #print('meet O')\n",
        "            # when meet O only record when the length more than one. ignore the 'only one'\n",
        "            if(current_length>=2):\n",
        "                end_position = index\n",
        "                article_result.append([atricle_id,start_position,end_position,entiy,entity_type])\n",
        "                #print('record:',[atricle_id,start_position,end_position,entiy,entity_type])\n",
        "            #record_entiy()\n",
        "\n",
        "            entiy = ''\n",
        "            start_position = 0\n",
        "            end_position = 0\n",
        "            current_length = 0\n",
        "            #reinit_parm()\n",
        "    return article_result\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abPtUWzMiVk4"
      },
      "source": [
        "from pandas import DataFrame\n",
        "import time  # 引入time模块\n",
        " \n",
        "def get_total_result(total_articles,model):\n",
        "    total_result = []\n",
        "    for article_index in range(len(total_articles)):\n",
        "      total_word_list = []\n",
        "      for sentence in test_data[article_index]:\n",
        "        total_word_list += sentence\n",
        "      total_label_tags = []\n",
        "      for predict in model.predict(test_data[article_index]):\n",
        "        total_label_tags += predict\n",
        "      #print(total_word_list)\n",
        "      #print(total_label_tags)\n",
        "      total_result += get_format_article_result(articleids[article_index],total_label_tags,total_word_list)\n",
        "      \n",
        "      #total_result += get_format_article_result(articleids[article_index],total_label_tags,total_word_list)\n",
        "    \n",
        "    result_df = DataFrame (total_result,columns=['article_id','start_position','end_position','entity_text','entity_type'])\n",
        "    #result_df['entity_text'] = result_df['entity_text'].apply(lambda x: s2t.convert(x))\n",
        "    #result_df.to_csv(checkpoint_dir_path+'/'+checkpoint_dir_path+'.tsv', sep = '\\t',index=False)\n",
        "    return result_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tipG-Jx-jPtF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "87fb05ac-c62d-40e9-c980-a6e5a4c6eb71"
      },
      "source": [
        "result_df = get_total_result(test_data,model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-63ead429ee67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_total_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qne6uLNjkHg8"
      },
      "source": [
        "result_df['entity_type'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7URMFQTIvfV"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_vgReRGIk9H"
      },
      "source": [
        "result_df.to_csv('result.tsv',sep='\\t',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}